<!doctype html><html lang="en"><head><title>Noel Varanda | App Performance Where We Go Wrong</title><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="description" content="Love anything front end, ranging user animations to asset bundling. Talk to me."><link rel="apple-touch-icon" sizes="180x180" href="/img/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/img/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/img/favicon-16x16.png"><link rel="manifest" href="/img/site.webmanifest"><link rel="mask-icon" href="/img/safari-pinned-tab.svg" color="#5bbad5"><meta name="msapplication-TileColor" content="#da532c"><meta name="theme-color" content="#ffffff"><meta property="og:title" content="App Performance Where We Go Wrong"><meta name="twitter:title" content="App Performance Where We Go Wrong"><meta property="og:description" content="Love anything front end, ranging user animations to asset bundling. Talk to me."><meta property="twitter:description" content="Love anything front end, ranging user animations to asset bundling. Talk to me."><meta property="og:image" content="https://noelvaranda.dev/img/headshot.jpg"><meta name="twitter:image" content="https://noelvaranda.dev/img/headshot.jpg"><meta name="twitter:card" content="summary_large_image"><meta property="og:url" content="/notes/202102121749/"><style>:root{--background:#fff;--background-meta:#f3f3f3;--text-primary:#111111;--text-secondary:#494949;--text-tertiary:#717171;--link:#29769c;--link-hover:#1d5069;--link-focus-bg:#fd0;--highlight-bg:#69d8bc;--red:#C5004A;--font-size-s:1.2rem;--font-size-m:1.5rem;--font-size-l:1.8rem;--font-size-xl:3rem}a[href]{color:var(--link);-webkit-tap-highlight-color:rgba(0,0,0,.3)}a[href]:focus:not(:focus-visible),button:focus:not(:focus-visible){outline:2px solid transparent}a[href]:focus{outline:2px solid orange}a[href]:hover{color:var(--link-hover)}a[href]:active{color:var(--text-primary)}a[href]:visited{text-decoration:underline}.highlight-line{display:block;padding:.125em 1em;text-decoration:none;color:inherit}.highlight-line:empty:before{content:" "}.highlight-line+br{display:none}.highlight-line-isdir{color:#b0b0b0;background-color:#222}.highlight-line-active{background-color:#444;background-color:hsla(0,0%,27%,.8)}.highlight-line-add{background-color:#45844b}.highlight-line-remove{background-color:#902f2f}code[class*=language-],pre[class*=language-]{color:#f8f8f2;background:0 0;text-shadow:0 1px rgba(0,0,0,.3);font-family:Consolas,Monaco,'Andale Mono','Ubuntu Mono',monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto;border-radius:.3em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#272822}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#8292a2}.token.punctuation{color:#f8f8f2}.token.namespace{opacity:.7}.token.constant,.token.deleted,.token.property,.token.symbol,.token.tag{color:#f92672}.token.boolean,.token.number{color:#ae81ff}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#a6e22e}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url,.token.variable{color:#f8f8f2}.token.atrule,.token.attr-value,.token.class-name,.token.function{color:#e6db74}.token.keyword{color:#66d9ef}.token.important,.token.regex{color:#fd971f}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.highlight-line{display:inline-block;text-decoration:none;color:inherit}.highlight-line:empty:before{content:" "}.highlight-line:not(:last-child){min-width:100%}.highlight-line .highlight-line:not(:last-child){min-width:0}.highlight-line-isdir{color:#b0b0b0;background-color:#222}.highlight-line-active{background-color:#444;background-color:hsla(0,0%,27%,.8)}.highlight-line-add{background-color:#45844b}.highlight-line-remove{background-color:#902f2f}.direct-link{font-family:sans-serif;text-decoration:none;font-style:normal;margin-left:.1em}a[href].direct-link,a[href].direct-link:visited{color:transparent}:hover>a[href].direct-link,:hover>a[href].direct-link:visited,a[href].direct-link:focus,a[href].direct-link:focus:visited{color:#aaa}.posts{list-style:none;padding:0;margin-top:40px}.posts__entry{position:relative;display:flex;padding:0 0 25px;line-height:2.4rem;flex-direction:column}@media screen and (min-width:40em){.posts__entry{padding:0 0 5px;flex-direction:row}}.posts__entry-date{width:120px;flex-shrink:0;display:inline-block;color:var(--text-tertiary)}table{margin:1em 0}table td,table th{padding-right:1em}.tag{display:inline-block;text-transform:uppercase;font-size:var(--font-size-s);padding:0 4px;margin-left:.8em;background-color:var(--red);color:var(--background);border-radius:.25em;text-decoration:none}a[href].tag,a[href].tag:visited{color:var(--background)}:root{--lightgray:#e0e0e0;--navy:#17050F;--blue:#082840;--app-width:650px}@media screen and (min-width:70em){:root{--app-width:715px}}*{box-sizing:border-box}body,html{padding:0;margin:0;font-family:HelveticaNeue-Light,"Helvetica Neue Light","Helvetica Neue",Helvetica,Arial,"Lucida Grande",sans-serif}html{font-size:62.5%}body{background-color:var(--background-primary);color:var(--text-secondary);line-height:2.1rem;font-size:var(--font-size-l);font-weight:400}::selection{background:var(--highlight-bg)}li,p{font-size:var(--font-size-l);line-height:3rem}p:last-child{margin-bottom:0}.app{display:flex;min-height:100vh;margin:0 auto}.app__gutter{display:none;position:relative;flex:0 0 auto;overflow:hidden}.app__gutter,.app__interactive{transition:flex 280ms ease-out}.app__interactive{display:flex;position:absolute;top:0;left:0;bottom:0;width:calc(1980px - var(--app-width) - 64px);transform:translateX(calc(-1 * (1980px - var(--app-width) - 64px)));transition:transform 280ms ease-out,background-color 280ms ease-out,box-shadow 280ms ease-out}.app__trigger{display:none;align-items:center;justify-content:center;height:100vh;box-sizing:border-box;background-color:#fff;width:64px;box-shadow:2px 0 2px rgba(0,0,0,.04);outline:0;border:none;cursor:pointer;z-index:2}.app__trigger:hover{box-shadow:4px 0 4px rgba(0,0,0,.04)}.app__trigger:hover path{stroke:var(--link)}.app__trigger:focus:not(:focus-visible) svg{outline:2px solid transparent}.app__trigger:focus svg{outline:3px solid orange;outline-offset:3px}.app__interactive-network{width:100%;height:100%;border:none;margin:0;padding:0;z-index:1;position:absolute;right:0;top:0;transition:transform 280ms ease-out,opacity 280ms ease-out}.app__interactive-network .vis-network:focus{outline:0}.app__main{display:flex;flex-direction:column;height:100vh;width:100%;padding:0 10px 30px;min-width:300px;box-sizing:border-box;flex:0 1 var(--app-width);transition:flex 280ms ease-out;background-color:#fff;margin:0 auto}@media screen and (min-width:70em){.app__gutter,.app__trigger{display:flex}.app_main{padding:0 30px 30px}}@media print{.app__gutter,.app__trigger{display:none}}@media screen and (min-width:40em){.app__main{padding:0 40px 50px}}.page-content{padding-bottom:80px}.content{margin:auto;padding:40px 20px;width:100%}@media screen and (min-width:40em){.blog-post{padding:40px 20px 140px}}.content__back{display:inline-block;margin:0 0 60px;height:20px}@media print{.content__back{display:none}}#page-back{visibility:hidden}.app--open .app__gutter{flex:1 1 auto}.app--open .app__interactive{transform:translateX(0);background-color:#f7f7f7;box-shadow:inset 30px -2px 74px -30px rgb(0 0 0 / 10%)}.app--open #page-back{visibility:visible}.app--open .app__interactive-network{display:block}h1{color:var(--text-primary);line-height:4rem;margin:20px 0 10px}h2{color:var(--text-primary);font-size:2.2rem;margin:80px 0 10px}img{max-width:100%}.paragraph--last{margin-bottom:50px}blockquote{font-style:italic;color:grey;margin:50px 0;position:relative}blockquote::before{content:'';position:absolute;border-left:4px solid #c2c2c2;height:100%;left:-20px;border-top-left-radius:4px;border-bottom-left-radius:4px}.time{margin-bottom:60px;display:block}@keyframes slidein{from{opacity:0;top:10%}to{opacity:1;top:0}}@media screen and (min-width:70em){.app--interactive{overflow:hidden;max-width:1980px}.app--interactive .app__main{overflow-y:auto;overflow-x:hidden;margin:0}}</style></head><body><main class="app app--interactive app--open"><div class="app__gutter" id="gutter" role="region" aria-labelledby="notes-trigger"><div class="app__interactive"><div id="network" class="app__interactive-network"></div></div></div><button class="app__trigger" id="notes-trigger" aria-label="Toggle notes archive" aria-expanded="true" aria-controls="gutter" data-open="true"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7 8L3 12L7 16" stroke="#333333" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/><path d="M17 16L21 12L17 8" stroke="#333333" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"/></svg></button><div class="app__main" id="app-main"><section class="content"><a href="/" class="content__back" id="page-back">Return back home</a><h1 id="page-title">App Performance Where We Go Wrong</h1><div class="page-content"><p class="paragraph">Everybody, consciously or not, loves performant applications, and as a consequence engineers spend a lot of time trying to assert visual stability, interactivity, fast loading times, amongst other aspects of performance when delivering features. There are a number of great resources out there telling us <em>why</em> performance is important, or <em>how</em> to make our applications performant, which I will link at the end of this post, but this post focuses on how we can improve performance without code.</p><p class="paragraph">Application performance does not start in code, it starts when an idea is conceived, and its expectations are set. We have a lot of useful&nbsp;metrics, auditors, strategies, debuggers, and tools&nbsp;that help us build highly performant applications. But what does it mean for an application to be "performant"?</p><p class="paragraph">A <em>behaviour-centric</em> page such as a dashboard with a lot of graphs may not need the most performant load time, but needs to be highly responsive. On the flip-side, a <em>content-centric</em> blog might not need every embedded video to be immediately interactive, but it needs page loads with the vital information to be shown speedily. Or if a user is told that a generated report will take up to 10 minutes to create - a relatively slow request time - it could be perceived as "fast" if it is done in 2 minutes.</p><p class="paragraph">Automating or ensuring "performant" apps at a code level is difficult as the definition of "performant" might not mean the same for every UI slice of an application; the way we measure a slice's performance is completely relative to what that slice needs or does. What this in turn means though is that standard performance auditors might not always paint a full picture. For example, a high score on page load speed using <a href="https://developers.google.com/web/tools/lighthouse">Lighthouse</a> can be insignificant if that isn't what the user needs to have an enjoyable experience.</p><p class="paragraph">By slicing our application into small slices from a user's perspective, we are able to understand how performant different parts of an application should be, and allocating useful metrics becomes easier. Deciding on how to slice an application is entirely on a company's needs/wants, and isn't to be confused with the way we slice <a href="https://martinfowler.com/bliki/BoundedContext.html">bounded context in Domain-driven design</a>, or how we slice micro-frontends, but could be similar.</p><p class="paragraph">Anytime we add functionality we can ask "what performance does this slice of UI need to provide an acceptable user experience?" and write these down somewhere company-visible. The solution to good performance could be a simple design, a fast API, or instant user response, it depends on what the user needs. The important part is that we are thinking and writing these up when the idea is conceived so that performance is centered around the&nbsp;<em>user</em>&nbsp;not the&nbsp;<em>function</em>. Performance is, and should be a cross-functional concern.</p><p class="paragraph">As we write more and more&nbsp;expectations of performance, the boundaries around slices of our application start to become more clear and we start to be able to be able to accurately justify what it means for our application to be "performant".</p><p class="paragraph">As a consequence of defining performance at a user level, it becomes easier to define and automate telemetry systems in code, or per service. We also now know what we should and shouldn't log, or should look out for in code reviews. So not only does centering performance at the idea inception stage help the <em>user</em>, we in turn make it easier to automate and assert it at a <em>function</em> level.</p></div></section></div><script type="module">import { createApp } from '/assets/bundle.22022024.js';

        createApp({"selectedNode":202102121749,"notes":{"nodes":[{"id":202101301828,"type":"note","bodyHtml":"<p class=\"paragraph\" >Micro frontends are an architectural approach to building user interfaces where applications are split into vertical slices (small domain-driven sections of an application); removing the need for a centralised front end team, and instead favouring small <a href=\"/notes/202101301829\" data-navigo>Cross Functional Teams</a>.</p>\n<p class=\"paragraph\" >Multiple codebases mean fewer lines of code per application; reducing the impact of tightly coupled code and bugs. This making it easier for teams to ship code without needing to coordinate with other teams. Smaller codebases also cater for rapidly changing tech due to a smaller blast radius when upgrading dependencies - updating the framework on a monolithic app, for instance, would be far more challenging. Lastly the lack of large teams means small architectural decisions can be made on the fly instead of in large meetings.</p>\n<p class=\"paragraph\" >Micro frontends are not a technical concept, they are an organisational, and <a href=\"/notes/202102071208\" data-navigo>Micro Frontend Architecture</a>. There are three essential concepts that glue different teams using micro frontends: <a href=\"/notes/202102280947\" data-navigo>Design Systems</a>, <a href=\"/notes/202102241823\" data-navigo>Micro Frontend Performance</a>, and <a href=\"/notes/202102281124\" data-navigo>Sharing Knowledge</a>.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 1-6)</li>\n</ul>","metaData":{"tags":["literature-note","index-card"]},"linksTo":[202101301829,202102071208,202102280947,202102241823,202102281124,"micro-frontends-in-action"],"label":"Micro Frontends"},{"id":202101301829,"type":"note","bodyHtml":"<p class=\"paragraph\" >Cross functional teams are interdisciplinary teams formed of members with a common goal. They include members from different departments of organisations, and aim to solve for slow communication lines caused by specialized teams.</p>\n<p class=\"paragraph\" >The main benefits are not only that features are faster to deliver due to the quick communication paths, but he user becomes the focus; as opposed to in specialised teams where the team's function is the focus. Adopting this strategy causes a small sacrifice for code quality, so adopting architectural patterns such as micro frontends can aid this.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (page 7)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202101301828,"micro-frontends-in-action"],"label":"Cross Functional Teams"},{"id":202102042224,"type":"note","bodyHtml":"<p class=\"paragraph\" >Server-side composition is the idea of composing markup from a number of micro frontends on the server. This technique can be used to improve user experience by bringing <a href=\"/notes/202102042246\" data-navigo>Server Markup Assembly Performance</a>.</p>\n<p class=\"paragraph\" >Leveraging server-side composition means that requests made to different servers to fetch micro frontend fragments of markup aren't limited by the client's bandwidth, which in turn can mean better load times for users. More techniques such as parallel loading, and streaming responses can further boost these low loading times.</p>\n<p class=\"paragraph\" >On the flip side multiple resources being fetched on the server also mean more points of failure therefore when composing markup. In order to avoid entire pages slowing down, or failing to load due to a flaky fragment, timeouts are used to give fragments time limits to load, and fallbacks are used to populate the markup in case the fragment doesn't load at all.</p>\n<p class=\"paragraph\" >When deciding on a server side composition architecture, teams must chose between a centralised approach or a distributed approach, where composition is nested in micro-frontends (see more on Podium).</p>\n<p class=\"paragraph\" >A few ways that server-side composition can be achieved include:\n    - <a href=\"/notes/202102071141\" data-navigo>NGINX Server-side Includes</a>\n    - <a href=\"https://github.com/zalando/tailor\">Tailor</a> #fe-library\n    - <a href=\"https://podium-lib.io/\">Podium</a> #fe-library </p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 59-69)</li>\n</ul>","metaData":{"aliases":["server-side rendering"],"tags":["literature-note"]},"linksTo":[202102042246,202102071141,202102071605,"micro-frontends-in-action"],"label":"Server-side Composition"},{"id":202102042232,"type":"note","bodyHtml":"<p class=\"paragraph\" >Client-side composition is the idea of assembling markup from a number of different micro-frontends on the user's device. Client-side rendered applications permit building rich and reactive user interfaces, so assembling micro frontends on the client leverages this benefit.</p>\n<p class=\"paragraph\" >Though client-side composition allows us to have an app-like feel, user experience is limited due to the asynchronous loading of fragments, causing a jumping UI. It also incurs an expensive load time due to JavaScript loading and running being dependent on a user's device.</p>\n<p class=\"paragraph\" ><a href=\"/notes/202102061841\" data-navigo>Micro Frontend Communication Patterns</a> is a major factor to consider when opting for client-side composition as when one micro frontend changes the others may need up react to this change too.</p>\n<p class=\"paragraph\" >A few ways that client-side composition can be achieved include:</p>\n<h4 id=\"usingiframes\">Using iframes</h4>\n<p class=\"paragraph\" >In its simplest form, composing different micro frontend fragments can be done using iframes to load in applications from different resources.</p>\n<p class=\"paragraph\" >Though iframes are a quick solution, the poor markup produced by iframes leads to issues with accessibility and SEO. Layout constraints also exist due outer layers needing to know the iframe's exact height to avoid scrollbars. Lastly there is a large performance overhead due to eac h iframe running in its own nested browsing context. #potential-fleet</p>\n<h4 id=\"usingajax\">Using Ajax</h4>\n<p class=\"paragraph\" >Ajax directly on the client code can be used to inject different micro-frontends into an application.</p>\n<p class=\"paragraph\" >Using Ajax has its benefits over using, for instance, iframes as it has a natural document flow, meaning its height does not need to be set by the outer container, and the markup is valid meaning better accessibility and SEO. Dealing with errors and failing fragments is also made easier (e.g. showing errors or adding placeholders) as the fragment is part of the outer layer's markup.</p>\n<p class=\"paragraph\" >However it causes difficulties in scoping, forcing us to require namespacing in CSS, cookies, events, and other browser globals. Furthermore any time something happens on one micro frontend, a server request is required to re-fetch the updated markup of the other micro frontends. Lastly knowing when scripts should be terminated is difficult causing memory management to be difficult.</p>\n<blockquote>\n  <p class=\"paragraph\" ><a href=\"https://github.com/gustafnk/h-include\">h-include</a> is a library which helps facilitate some of the setup and pain points caused by Ajax. #fe-library</p>\n</blockquote>\n<h4 id=\"usingwebcomponents\">Using Web components</h4>\n<p class=\"paragraph\" >Custom elements offer the major advantage of business logic encapsulation, and come equipped with lifecycle methods which can be used to determine whether they have been created, updated, or destroyed. As such they can be leveraged as a technology-neutral interface when implementing a micro frontend. The Shadow DOM can be leveraged to ensure styles do not leak across different parts of an application - avoiding the need for policing of namespaces.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 85-99)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202102061841,202102071605,"micro-frontends-in-action"],"label":"Client-side Composition"},{"id":202102042246,"type":"note","bodyHtml":"<p class=\"paragraph\" >When composing markup on the server, a number of techniques can be used to mitigate for the effect of misbehaving fragments, which can cause performance or the user's experience to degrade.</p>\n<h3 id=\"loadingfragmentsinparallel\">Loading fragments in parallel</h3>\n<p class=\"paragraph\" >By loading all fragments in parallel, the loading time will only be as slow as time taken to load the slowest fragment, as opposed to a sum of all fragments.</p>\n<h3 id=\"avoidingnestedfragments\">Avoiding nested fragments</h3>\n<p class=\"paragraph\" >Nesting fragments can potentially increase response time as loading in parallel cannot be done for all fragments. Avoiding nested fragments can therefore mean faster response times.</p>\n<h3 id=\"deferringloadingtoclientside\">Deferring loading to client-side</h3>\n<p class=\"paragraph\" >This technique is used to deffer specific fragments to load on the client-side instead of the server. This means we leverage the server for essentials (E.g. what is in the user's viewport), and offload non-essentials to load after the user is able to see the page.</p>\n<h3 id=\"streamingresponses\">Streaming responses</h3>\n<p class=\"paragraph\" >This is the concept of sending parts of the response at a time, as they are resolved. Doing so means the first transfer to the browser is made as soon as the first part is resolved, making the Time-to-first-byte very fast for the user. </p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 69-81)</li>\n</ul>","metaData":{"tags":["literature-note","performance"]},"linksTo":[202102042224,"micro-frontends-in-action"],"label":"Server Markup Assembly Performance"},{"id":202102061841,"type":"note","bodyHtml":"<p class=\"paragraph\" >Clearly defined communication paths and boundaries are necessary to assure state is consistent and loosely coupled across micro frontends. Fragments need to be able to communicate to their parents, and each other, and global context needs to persist across all fragments. Rules surrounding events, boundaries, loading times, and state should be considered in communication. </p>\n<p class=\"paragraph\" >Events should be seen as notifications, and avoid being used to transfer data. The more data we transfer in an event, the more dependency we have on external events to make our micro frontend work. So simple nudges are best suited.</p>\n<p class=\"paragraph\" >Micro frontends are supposed to be well contained, so too much communication to other micro frontends could be indicative of poorly defined boundaries. It is therefore extremely important to define the boundaries of micro frontends before starting to build them.</p>\n<p class=\"paragraph\" >Asynchronous loading of fragments means not all fragments might have loaded when an event is sent. Standard events could therefore not suffice to update different micro frontends if one has not loaded in time. For example if micro frontend #1 updates, and micro frontend #2 needs to react to this change but has not yet loaded this could cause inconsistency.</p>\n<p class=\"paragraph\" >Lastly, as tempting as it may be to use stores and API calls that persist across micro frontends, it is important to keep these separate as sharing state and stores causes for tight coupling. For example if micro frontend #1 wanted to change the structure of their store but micro frontend #2 was also using this, then there would need to be unnecessary communication and accord to do so. A small duplication is sometimes better than the wrong abstraction. #potential-fleet</p>\n<h3 id=\"parenttochildchildtoparent\">Parent to child / child to parent</h3>\n<p class=\"paragraph\" >Parent to fragment communication can be done using the \"props down, events up\" technique, where a parent communicates to fragments via their attributes, and the vice-versa is done using native events.</p>\n<h3 id=\"siblingtosibling\">Sibling to Sibling</h3>\n<p class=\"paragraph\" >Communication between siblings is sometimes necessary when one part of the app needs to talk to the other but the logic does not make sense to reside in a parent.</p>\n<p class=\"paragraph\" >Direct communication (E.g. traversing a DOM tree) causes tight coupling, meaning if one of the siblings changes then the other will break too. Using an event-bus/broadcasting model allows siblings to publish and subscribe to actions without knowing about what other siblings may be using them, allowing fragments to communicate to each other without coupling. The <strong>Broadcast API</strong> is a native browser feature that allows this, and persists across pages/tabs.</p>\n<h3 id=\"globalcontext\">Global context</h3>\n<p class=\"paragraph\" >Managing global context such as <strong>authentication</strong> can be done leveraging proxies which inject context into HTTP response headers when information comes from server, or a global JavaScript API if the information is on the UI. An <a href=\"/notes/202102062302\" data-navigo>App Shells</a> is a common place to house this sort of information.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 99-117)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202102062302,"micro-frontends-in-action"],"label":"Micro Frontend Communication Patterns"},{"id":202102062241,"type":"note","bodyHtml":"<p class=\"paragraph\" >Routing navigation and transitions is one of the main considerations when integrating multiple micro frontends into a single application. It can be accomplished in simple but limiting ways by using links, or more complex but user-rich experiences by using app shells.</p>\n<h3 id=\"routingusinglinks\">Routing using links</h3>\n<p class=\"paragraph\" >At its simplest form routing between micro front ends can be implemented by hosting two different Web pages to serve different applications.</p>\n<h3 id=\"routingontheserver\">Routing on the server</h3>\n<p class=\"paragraph\" >A proxy layer, using for instance NGINX, can be used to unify URLs under one domain. This comes with various limitations such as micro frontends being restricted to pages, duplication of common sections (e.g. navbars), and hard navigation (pages fetched from server) between pages.</p>\n<h3 id=\"routingusinganappshell\">Routing using an app shell</h3>\n<p class=\"paragraph\" >The three aforementioned problems can be solved by using an app shell - a parent application for all micro frontends.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 26, 51-63, and 118-145)</li>\n</ul>","metaData":{"aliases":["routing"],"tags":["literature-note"]},"linksTo":[202102071208,202102071240,"micro-frontends-in-action"],"label":"Micro Frontend Routing"},{"id":202102062302,"type":"note","bodyHtml":"<p class=\"paragraph\" >An app shell acts as a parent application for all micro frontends. It should not contain any business logic; instead the app shell has two main responsibilities: <a href=\"/notes/202102072253\" data-navigo>Micro Frontends Asset Loading</a> and <a href=\"/notes/202102071240\" data-navigo>Routing Using an App Shell</a> between pages.</p>\n<p class=\"paragraph\" >Other common features that appear in app shells include: </p>\n<ul>\n<li>Authentication.</li>\n<li>Tracking managers and analytics.</li>\n<li>Performance monitoring.</li>\n<li>Error reporting.</li>\n</ul>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages )</li>\n</ul>","metaData":{"tags":["literature-note","reference-note"]},"linksTo":[202102072253,202102071240,"micro-frontends-in-action"],"label":"App Shells"},{"id":202102071117,"type":"note","bodyHtml":"<p class=\"paragraph\" >Universal rendering combines both client- and server-side rendering to leverage the advantages giving the user the quick load times of server-side composition, and the interactive app-feel of client-side composition.</p>\n<p class=\"paragraph\" >Universal rendering requires micro frontends to be able to be rendered on both the server, and the client. This is difficult when using native elements such as iframes or Web components as these don't render on the server, but can be mitigated by using a combination of Web components on the client side and SSI on the server-side, or using front end frameworks such as Reach which provide this functionality out of the box.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 145-155)</li>\n</ul>","metaData":{"aliases":["Server-side Rendering","Isomorphic Rendering"],"tags":["literature-note"]},"linksTo":[202102042224,202102042232,"micro-frontends-in-action"],"label":"Universal Rendering"},{"id":202102071141,"type":"note","bodyHtml":"<p class=\"paragraph\" ><a href=\"https://www.nginx.com/\">NGINX</a> is equipped with SSI (server side includes); placeholders put in code with a URL which when resolved by NGINX will be replaced with the markup outputted.</p>\n<p class=\"paragraph\" >When adopting SSI, timeouts and fallbacks are used to avoid entire pages failing slowing down, or failing to load due to a flaky fragment.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 51-58)</li>\n</ul>","metaData":{"aliases":["SSI"],"tags":["literature-note","fe-library"]},"linksTo":[202102042224,"micro-frontends-in-action"],"label":"NGINX Server-side Includes"},{"id":202102071208,"type":"note","bodyHtml":"<p class=\"paragraph\" >Micro frontends can be implemented a number of ways ranging linking pages to delivering unified universal SPAs. Different approaches often depend on what is required, and are defined by the approaches chosen to route and compose the application.</p>\n<p class=\"paragraph\" >The way each micro frontend needs to be <a href=\"/notes/202102071605\" data-navigo>Micro Frontend Composition</a>, in conjunction with how we need to <a href=\"/notes/202102062241\" data-navigo>Micro Frontend Routing</a> helps indicate the best way to architect each one.</p>\n<p class=\"paragraph\" >There are six main architectural approaches that can be used (each higher in complexity than the one before):</p>\n<ol>\n<li><strong><a href=\"/notes/202102062241\" data-navigo>Micro Frontend Routing</a></strong></li>\n<li><strong><a href=\"/notes/202102062241\" data-navigo>Micro Frontend Routing</a></strong></li>\n<li><strong>Linked SPAs</strong> (Hard navigation between multiple SPAs).</li>\n<li><strong>Linked Universal SPAs</strong> (Hard navigation between multiple SPAs with universal rendering).</li>\n<li><strong><a href=\"/notes/202102071240\" data-navigo>Routing Using an App Shell</a></strong> (One SPA (app shell) composed of multiple SPAs).</li>\n<li><strong>Unified Universal SPA</strong> (One SPA (app shell) composed of multiple SPAs with universal rendering).</li>\n</ol>\n<p class=\"paragraph\" >To help decide which is the best approach, we can use the <a href=\"https://www.manning.com/books/micro-frontends-in-action\">Documents-to-Application Continuum</a> to decide if we need server-side, client-side, or universal rendering. This <a href=\"https://freecontent.manning.com/wp-content/uploads/which-techniquearchitecture-is-right-for-my-project_06.jpg\">linked decision tree</a> can be used in combination with the continuum to make a decision on what each micro frontend needs from a user's perspective.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 160-161)</li>\n</ul>","metaData":{"tags":["literature-note","architecture"]},"linksTo":[202102071605,202102062241,202102071240,"micro-frontends-in-action"],"label":"Micro Frontend Architecture"},{"id":202102071240,"type":"note","bodyHtml":"<p class=\"paragraph\" >Leveraging an app shell can be a powerful tool to make navigating between micro frontends seemless</p>\n<h3 id=\"singlelevelrouting\">Single-level routing</h3>\n<p class=\"paragraph\" >In a single-level routing model, the app shell will load the code for each of the micro frontends, as well as host configuration for all of the routes of an application. The configuration can be something as simple as a key/value store mapping URLs to component names (this example uses custom elements):</p>\n<pre class=\"language-markup\" ><code class=\"ts language-ts\">const routes = {\n  '/checkout/payments': 'custom-element-from-first-micro-fe',\n  '/checkout/shipping': 'another-element-from-first-micro-fe',\n  '/survey/creator': 'ace-element-from-second-micro-fe',\n  '/survey/results': 'king-element-from-second-micro-fe'\n}\n</code></pre>\n<p class=\"paragraph\" >Routing logic is then inserted (using for example the native history API or a library) where page links are intercepted and using the configuration above the app shell will fetch the appropriate code (in this example; custom element) for the route.</p>\n<p class=\"paragraph\" >The main issue with this way of routing is the fact that anytime micro frontend needs to add routes, they need to add to the app shell. Any routing logic also needs to reside in the app shell, which when micro frontend-specific can mean that business logic is leaking into the supposedly feature-agnostic layer.</p>\n<h3 id=\"twolevelrouting\">Two-level routing</h3>\n<p class=\"paragraph\" >Two level routing divides routing into app shell-, and micro fronted-level routing. The app shell level router, or top level router, houses simple sections.</p>\n<pre class=\"language-markup\" ><code class=\"ts language-ts\">const routes = {\n  '/checkout': 'custom-element-first-micro-fe',\n  '/survey': ''custom-element-second-micro-fe'\n}\n</code></pre>\n<p class=\"paragraph\" >Once this is done, then different micro frontends can implement their section-level routes using the different technologies they desire (e.g. vue-router on <code>/checkout</code> and react-router on <code>/survey</code>).</p>\n<p class=\"paragraph\" >When using an app shell to route, it is always important to remember to cleanup any listeners once tfhe micro frontend has been disconnected in order to avoid memory leaks.</p>\n<h3 id=\"libraries\">Libraries</h3>\n<ul>\n<li><a href=\"https://single-spa.js.org/\">single-spa</a> acts as an app shell out of the box. Different micro frontends expose their code using a common interface, and register their base route on on the app shell. Single-spa also handles topics such as error handling or lazy loading. #fe-library </li>\n</ul>\n<h3 id=\"importanttopicstoconsider\">Important topics to consider</h3>\n<ul>\n<li>Shared HTML document and meta data.</li>\n<li>Memory management and clean up.</li>\n<li>App shell is a single point of failure, so heavy testing and good architecture are vital.</li>\n<li>Boot time of different micro frontends.</li>\n</ul>\n<h2 id=\"references\">References</h2>","metaData":{"aliases":["Stitching Layer"],"tags":["literature-note"]},"linksTo":[202102062241,202102062302],"label":"Routing Using an App Shell"},{"id":202102071605,"type":"note","bodyHtml":"<p class=\"paragraph\" >In practice different micro frontends are bound to appear on the same page. An example is when showing a header bar next to page content, or nested fragments. Composition  techniques can be grouped into <a href=\"/notes/202102042224\" data-navigo>Server-side Composition</a> and <a href=\"/notes/202102042232\" data-navigo>Client-side Composition</a> composition.</p>\n<p class=\"paragraph\" >These techniques help us understand how to compose micro frontends on either individually. A more common way of composing is by using <a href=\"/notes/202102071117\" data-navigo>Universal Rendering</a>.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (page 158)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202102042224,202102042232,202102071117,202102071208,"micro-frontends-in-action"],"label":"Micro Frontend Composition"},{"id":202102072253,"type":"note","bodyHtml":"<p class=\"paragraph\" >Loading asset bundles from multiple micro frontends can be a challenging task. We need to ensure <a href=\"/notes/202102121403\" data-navigo>Asset Bundle Granularity</a> to cater for <a href=\"/notes/202102241823\" data-navigo>Micro Frontend Performance</a> and team autonomy. However ensuring different micro frontends can deploy independently, deprecated cached assets need to be cache-busted on user's machines, and asset synchronization during deployments are all accounted for.</p>\n<p class=\"paragraph\" >Two main considerations need to accounted for when loading assets; cache-busting to ensure the user always sees the latest version, and synchronization to assert that rolled deployments do not cause 404 errors.</p>\n<ul>\n<li><a href=\"/notes/202102281315\" data-navigo>Cache Busting</a></li>\n<li><a href=\"/notes/202102281316\" data-navigo>Deployment Synchronization</a></li>\n</ul>\n<p class=\"paragraph\" >In order to guarantee the user's resources are cache busted, and synchronization is accounted when deploying, each micro frontend can provide a <code>manifest.json</code>. This manifest should contain links to the static resources, as well as the version it is providing.</p>\n<pre class=\"language-markup\" ><code>{\n  version: 1,\n  css: 'my-css.123.css',\n  js: 'my-js.123.js',\n}\n</code></pre>\n<p class=\"paragraph\" >When the HTML content is fetched, a <code>version</code> is returned in the header, when we look at our cached <code>manifest.json</code>, we compare its version to the one returned in the HTML response. If they don't match then we request a new <code>manifest.json</code> and update it. </p>\n<blockquote>\n  <p class=\"paragraph\" ><a href=\"https://podium-lib.io/\">Podium</a> provides out-of-the-box functionality for creating versioned manifests. #fe-library</p>\n</blockquote>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong></li>\n</ul>","metaData":{"tags":["literature-note","caching","assets"]},"linksTo":[202102121403,202102241823,202102281315,202102281316,"micro-frontends-in-action"],"label":"Micro Frontends Asset Loading"},{"id":202102121403,"type":"note","bodyHtml":"<p class=\"paragraph\" >Bundle granularity referrers to how big or small static assets served to a user should be. Front end chapters can choose to serve assets by sections or fragments, or anywhere in between, but performance should be considered when doing so. </p>\n<p class=\"paragraph\" >Picking the right granularity is essential as it allows teams to understand how they need to use their code. Picking a single shared bundle might make setup costs easier and concepts like tree-shaking easier to achieve, however come at the cost of tight coupling. On the flip-side, having granular bundles may incur more files to download for the user, but techniques such as on-demand loading can help mitigate these</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 186-189)</li>\n</ul>","metaData":{"tags":["literature-note","performance","assets"]},"linksTo":[202102072253,"micro-frontends-in-action"],"label":"Asset Bundle Granularity"},{"id":202102121749,"type":"note","bodyHtml":"<p class=\"paragraph\" >Everybody, consciously or not, loves performant applications, and as a consequence engineers spend a lot of time trying to assert visual stability, interactivity, fast loading times, amongst other aspects of performance when delivering features. There are a number of great resources out there telling us <em>why</em> performance is important, or <em>how</em> to make our applications performant, which I will link at the end of this post, but this post focuses on how we can improve performance without code.</p>\n<p class=\"paragraph\" >Application performance does not start in code, it starts when an idea is conceived, and its expectations are set. We have a lot of useful&nbsp;metrics, auditors, strategies, debuggers, and tools&nbsp;that help us build highly performant applications. But what does it mean for an application to be \"performant\"?</p>\n<p class=\"paragraph\" >A <em>behaviour-centric</em> page such as a dashboard with a lot of graphs may not need the most performant load time, but needs to be highly responsive. On the flip-side, a <em>content-centric</em> blog might not need every embedded video to be immediately interactive, but it needs page loads with the vital information to be shown speedily. Or if a user is told that a generated report will take up to 10 minutes to create - a relatively slow request time - it could be perceived as \"fast\" if it is done in 2 minutes.</p>\n<p class=\"paragraph\" >Automating or ensuring \"performant\" apps at a code level is difficult as the definition of \"performant\" might not mean the same for every UI slice of an application; the way we measure a slice's performance is completely relative to what that slice needs or does. What this in turn means though is that standard performance auditors might not always paint a full picture. For example, a high score on page load speed using <a href=\"https://developers.google.com/web/tools/lighthouse\">Lighthouse</a> can be insignificant if that isn't what the user needs to have an enjoyable experience.</p>\n<p class=\"paragraph\" >By slicing our application into small slices from a user's perspective, we are able to understand how performant different parts of an application should be, and allocating useful metrics becomes easier.  Deciding on how to slice an application is entirely on a company's needs/wants, and isn't to be confused with the way we slice <a href=\"https://martinfowler.com/bliki/BoundedContext.html\">bounded context in Domain-driven design</a>, or how we slice micro-frontends, but could be similar.</p>\n<p class=\"paragraph\" >Anytime we add functionality we can ask \"what performance does this slice of UI need to provide an acceptable user experience?\" and write these down somewhere company-visible. The solution to good performance could be a simple design, a fast API, or instant user response, it depends on what the user needs. The important part is that we are thinking and writing these up when the idea is conceived so that performance is centered around the&nbsp;<em>user</em>&nbsp;not the&nbsp;<em>function</em>. Performance is, and should be a cross-functional concern.</p>\n<p class=\"paragraph\" >As we write more and more&nbsp;expectations of performance, the boundaries around slices of our application start to become more clear and we start to be able to be able to accurately justify what it means for our application to be \"performant\".</p>\n<p class=\"paragraph\" >As a consequence of defining performance at a user level, it becomes easier to define and automate telemetry systems in code, or per service. We also now know what we should and shouldn't log, or should look out for in code reviews. So not only does centering performance at the idea inception stage help the <em>user</em>, we in turn make it easier to automate and assert it at a <em>function</em> level.</p>","metaData":{"tags":["permanent-note","performance","article"]},"linksTo":[202102241823],"label":"App Performance Where We Go Wrong"},{"id":202102131048,"type":"note","bodyHtml":"<p class=\"paragraph\" >One of the benefits of working at Attest is its 10% time; as an employee you can optionally take 10% of your time to go off and better either yourself or the company. This is quite common amongst tech companies, and in fact Gmail and Maps were both invented in Google's 20% time. It's that short period of time where you're not bound to team responsibilities, or deadlines, and can focus solely on what you (or a team of you) think will improve the platform or yourselves. This short post goes into where I spent my 10% time; what I am proud of, what I regret, and what I would have done differently.</p>\n<p class=\"paragraph\" >I used to have regular meetings with the COO of Attest - a lot of people did. In these meetings there was an indirect, and underlying set of questions on his side:</p>\n<blockquote>\n  <p class=\"paragraph\" >Where is the front end chapter now?\n  Where does it need to be?\n  What do we need to do to get where it needs to be?</p>\n</blockquote>\n<p class=\"paragraph\" >I found that the first question was an easy one to answer as I lived through it daily, but couldn't answer the second and third questions with nearly as much clarity. And there was frustration, notably, from both parts; my boss couldn't see where the front end needed to be, nor did I have the certainty to tell him with confidence what we needed to do to get there. I used to truly believe and tell him that if we wanted to drive forward as a chapter, then we would need to hire someone very senior that could teach us.</p>\n<p class=\"paragraph\" >Whilst all this was happening, I decided that I wanted to pursue new opportunities in another country, and so handed my notice in at Attest - a company for which I cannot recommend enough to work at. My notice period, three months, gave me a lot of time to think about what it is I liked about myself at Attest, and what it was that didn't like. Who was it that I wanted to be at my next work place? It dawned on me that the person I wanted to be was someone who would be able to easily answer those two questions that I couldn't: Where does the front end chapter need to get to, and how do we get there?</p>\n<p class=\"paragraph\" >I've always thought of myself as a good engineer, have read the \"bibles\" of software engineering, and keep up to date with latest tech. But I wanted to level up, and I did some things which I had rarely done in the past; I bought a number of books on micro frontend architecture, cross-functional squads and scaling front end teams (technical books are something I had previously underestimated, and used more as reference points) and I started listening to podcasts, and really explored the depths and crevices of a lot of major frameworks' codebases. I'm not saying I had never read books, or listened to podcasts, or explored codebases before, but now I explicitly dedicated time to improve myself in areas I knew I hadn't explored to their fullest.</p>\n<p class=\"paragraph\" >In my mind I started to build a much clearer mental model as to how a front end system can scale, and found more confidence in my opinions. Most importantly, I felt as though those two questions which I looked at with such hesitation were now not as scary. I'm not saying I understand exactly how to answer them in any way or form, but I feel like I started to <a href=\"https://www.forbes.com/sites/brucekasanoff/2018/03/21/you-dont-know-what-you-dont-know/?sh=22cfe82f573d\">know what I didn't know</a>.</p>\n<p class=\"paragraph\" >I started at Attest when it was a small company of nine, and it's now grown to house over one hundred and thirty employees, with a global client base. We've been through a lot, and I like to think I've been an important asset at times. We started out as two front end engineers, and are now a team of twelve, which comes with difficult decisions, both technically and culturally. But over the past few months, where I've started to dedicate focused time to work on myself and limitations in my own knowledge, I have realised one major perspective that I hadn't before: that the path we've come from to where we are now is far shorter than the path between where we are now, to where we need to get to.</p>\n<p class=\"paragraph\" >Now, where I wanted to get to with this post. I would rarely take my 10% time, and when I did it would be to fix a part of the product that had bugged me for a while. I would improve aspects of our&nbsp;<a href=\"https://developer.mozilla.org/en-US/docs/Learn/Performance/perceived_performance\">perceived performance</a>&nbsp;and I introduced fragments of&nbsp;<a href=\"https://www.smashingmagazine.com/2016/11/true-lies-of-optimistic-user-interfaces\">optimistic UI</a>, as well as a few other things I'm proud of. </p>\n<p class=\"paragraph\" >But in these two months leading up to my leaving date, I feel much more confident in answering those two questions that have been at the back of my mind. I now have a more comprehensive understanding of how a chapter can evolve, I have a better grasp of what the unknowns might be, and I have gained a much clearer view of what it is that I don't know.</p>\n<p class=\"paragraph\" >It's very easy to get absorbed in the products you are working on, it's only natural as you work on them all day, every day. So when given time to \"improve the product\", one's natural instinct can very often be inclined to automating something that directly affects their work, or improving that part of the product they didn't like. However something I wish I had learned a lot sooner was that a lot of the time by introspecting and understanding your own knowledge gaps and trying to learn how to better yourself in those areas, you will inevitably become a stronger asset to the company you work for. So my suggestion is that if you work at a company as awesome as Attest, which offers 10% time, introduce concepts you feel are missing from the product, but also look outside of the company-spectrum for while, and use that 10% to focus on bettering yourself. It will make you a better, or more knowledgeable person, which in turn will make the company a better one too.</p>","metaData":{"tags":["permanent-note"]},"linksTo":[202102241726],"label":"The Value of 10% Time"},{"id":202102241726,"type":"note","bodyHtml":"<p class=\"paragraph\" >I recently started a new way of memorizing the things I learn, which is essentially to write them in my own words as soon as I read them.</p>\n<p class=\"paragraph\" >I follow the <a href=\"https://en.wikipedia.org/wiki/Zettelkasten\">Zettelkasten</a> method of taking notes. Take a peek at the notes I've kept and how they connect to each other.</p>\n<p class=\"paragraph\" >My hope is that one day, eventually my zettelkasten will be big enough that it can be of use to other people. This is <strong>still very bare</strong>, I plan on adding to it as I read (and note down) more.</p>\n<h3 id=\"howtouseit\">How to use it</h3>\n<p class=\"paragraph\" >Easy. Click on the nodes on the right hand side. Colours represent their \"tags\", and the links recommend the next node. I plan on adding better visualisation in the future so hang on tight.</p>\n<h3 id=\"shoutout\">Shout out</h3>\n<p class=\"paragraph\" >All reference you see right now are from Michael Geers' <a href=\"https://www.manning.com/books/micro-frontends-in-action\">Micro Frontends in Action</a>, so thank you for being my first reference guide.</p>","metaData":{"tags":["index-card"]},"linksTo":[202101301828],"label":"Notes Archive"},{"id":202102241823,"type":"note","bodyHtml":"<p class=\"paragraph\" >When multiple teams are injecting their code into a page on an application, understanding what the performance for that page should be, or who owns that is difficult. Different pages of an application require different metrics depending their use case.</p>\n<blockquote>\n  <p class=\"paragraph\" >Autonomy inherently comes with the cost of accepting redundancy</p>\n</blockquote>\n<p class=\"paragraph\" >Teams define performance budgets on their pages and make sure to constantly measure that the page is within those budgets. If a micro frontend within that page breaks that budget, then the team owning the page should stop to fix it. Given multiple micro frontends can exist on a page, it's difficult to allocate budgets per micro frontend so it is important that the team that owns the page is responsible for making sure the different micro frontends are within budgets.</p>\n<p class=\"paragraph\" >Performance benefits of micro frontends include the fact that they naturally invoke granular asset bundles, and their narrow scope and small code surface area enables both architectural and software choices to be centered around their needs, not to mention the fact that developers naturally know everything there is to about the codebase.</p>\n<p class=\"paragraph\" >The amount of code each team has can also affect performance. Performance can be improved by extracting shared dependencies from micro frontends and housing them in one central place, for example a shared framework. It is important to measure the cost of performance vs the cost of autonomy when doing this however as forcing teams to share frameworks and versions can be a massive deficit on autonomy. For example, if one team wants to use Vue 2, but the other Vue 3 this should be allowed as otherwise if both (or more) teams have to share the same version of Vue, then upgrading to Vue 3 will require a lot of communication and coordination between teams which will slow them down. </p>\n<blockquote>\n  <p class=\"paragraph\" ><a href=\"https://webpack.js.org/plugins/dll-plugin/\">Webpack's D11Plugin</a> is a useful plugin to help extract shared dependencies across bundles. #fe-library </p>\n</blockquote>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (page 191-212)</li>\n</ul>","metaData":{"tags":["literature-note","performance"]},"linksTo":[202102121403,202102121749,"micro-frontends-in-action"],"label":"Micro Frontend Performance"},{"id":202102280947,"type":"note","bodyHtml":"<p class=\"paragraph\" >Design systems are systems containing <em>tokens</em> (fonts, colours, icons, etc.), <em>components</em>, and more <em>advanced patterns</em> (tooltips, layers, etc.). Their goal is to create consistency across a product (or products) in the way it looks and feels, and speed up development by offering engineers out-of-the-box functionality.</p>\n<p class=\"paragraph\" >Design systems inevitably cause coupling between teams as they all rely on it to create their part of the product so it is important to architect it right from the beginning as changes down the line can be cumbersome.</p>\n<p class=\"paragraph\" >They can be implemented at runtime, such as Twitter's Bootstrap, where all teams are forced to use the latest version, or they can be versioned, using the entire library or each component. Versioning leads to slower rollouts and eventual consistency, but allows teams to develop at their own speed and reduces the risk of bugs.</p>\n<p class=\"paragraph\" >Lastly, components in a design system can be framework-specifc or -agnostic.  The advantage of having framework-specific components is that they're easier to implement, and work both server- and client-side, however they require teams to use the same framework. Framework-agnostic components mean all teams have access to these, however require adapter layers and are limited to client-side rendering. Other alternatives include having multiple framework-specific components, which is more work but means out-of-the-box functionality for all teams, or having a common <em>templating language</em> (E.g. JSX). This last one means all teams are compatible however you can't include behavior specific to that component.</p>\n<p class=\"paragraph\" >The most important aspect to a design system is to acknowledge that there will be change so keeping the system simple, and open to this change is vital. This can be done by keeping components \"dumb\" is essential, e.g. using only Atoms and Molecules from the Atomic design principles, and making sure components belong in the component library and are not domain-specific.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 213-235)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202101301828,"micro-frontends-in-action"],"label":"Design Systems"},{"id":202102281039,"type":"note","bodyHtml":"<p class=\"paragraph\" >Micro frontends bring a technical benefit, however the biggest benefit they bring is organisational. If boundaries are correctly allocated, then teams should not cross paths too often making them truly autonomous.</p>\n<p class=\"paragraph\" >Often-times micro frontends are considered to be a technical implementation for the frontend chapter to make. The company's squads don't have bounded context; all teams own all code and parts of the product. This is done so that any product team can feel empowered to change any part of any of our products however this couldn't be further from the truth.</p>\n<p class=\"paragraph\" >What this actually means is that engineering micro-services and -frontends have not been divided with the squads in mind and engineers are forced to require community, federation, and organisational hierarchy around these which is a massive slow down.</p>\n<p class=\"paragraph\" >In order to create fully autonomous teams, micro-frontends need to be created by and for specific teams. Identifying team boundaries can be done by following the principles of Domain-driven design, where by creating a <em>ubiquitous language</em> across a company, then identifying the <em>bounded contexts</em> becomes fairly obvious. </p>\n<p class=\"paragraph\" >Having clear boundaries allows organisations to scale faster by hiring for teams instead of for the company. It enables creativity as teams are able to build what they want, how they want. And it allows for failing fast as teams are able to add hacky code which they can later tare down.</p>\n<p class=\"paragraph\" >Creating fully autonomous teams can cause difficulties in <a href=\"/notes/202102281124\" data-navigo>Sharing Knowledge</a> but there are a lot of known ways to mitigate these issues.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 236-150)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202102281124,"micro-frontends-in-action"],"label":"Teams and Boundaries"},{"id":202102281124,"type":"note","bodyHtml":"<p class=\"paragraph\" >When implementing <a href=\"/notes/202101301828\" data-navigo>Micro Frontends</a>, if teams are truly autonomous and have been given <a href=\"/notes/202102281039\" data-navigo>Teams and Boundaries</a>, then their lines of communication are minimal. This proves one major difficulty which is sharing knowledge across teams. If team and guaranteeing teams are helping to educate each other; how do we guarantee teams aren't solving the same problems (from a technical standpoint)?</p>\n<p class=\"paragraph\" >This is where the concept of <em>guilds</em> comes into play; guilds are a rooms for people across teams to share knowledge about cross-cutting concerns (for example accessibility, or performance). Some tougher, real-life examples such as infrastructure can be solved a few ways; either you have a central infrastrcuture team, or each team is responsible for their own infrastructure, or each product team owns a \"part\" of the infrastructure and it is managed through federation.</p>\n<p class=\"paragraph\" >Even though with micro frontends, technology should be diverse it is always good to have a \"toolbox\" and defaults for consistency across teams. This toolbox can include frontend blueprints; setting up technical aspects such as directory structure, testing, linting, API communication. Alternatively it can include bundlers, or liniting tools too. These are all optional and at teams' disposal.</p>\n<p class=\"paragraph\" >It is necessary for teams to have sufficient autonomy so that they can change direction if they like, but also keep as close to a \"way of the organisation\" as possible; there is value in similarity.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 236-250)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":[202101301828,202102281039,"micro-frontends-in-action"],"label":"Sharing Knowledge"},{"id":202102281315,"type":"note","bodyHtml":"<p class=\"paragraph\" >Most browsers (and applications) are optimised to cache static assets (images, CSS files, JavaScript, etc.) on a user's machine. This is a verified way to increase performance, however causes difficulties providing files when continuous deployment is a business requirement. For example exposing a file called <code>fragment.css</code> will no longer suffice as it will be cached on a user's machine, and updates to <code>fragment.css</code> will not reflect on that user's machine. In order to assert that a file gets cached, a technique called \"cache busting\" is used where a fingerprint is added to the end of the URL (E.g. <code>fragment.72.js</code>). Each subsequent deployment will add a new fingerprint.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 174-176)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":["micro-frontends-in-action"],"label":"Cache Busting"},{"id":202102281316,"type":"note","bodyHtml":"<p class=\"paragraph\" >In order to deal with high amounts of traffic, applications usually run multiple instances, and a load balancer is then used to distribute requests evenly across these instances. As new versions of an application are deployed, their instances are replaced with new instances, one-by-one to assert most instances are running at once.</p>\n<p class=\"paragraph\" >The downside to replacing instances one-by-one is that whilst deploying new versions, the resources provided by each instance could differ. For example if a deployment is undergoing and one instance has been replaced, but the rest haven't, then one instance might serve <code>fragment.74.js</code>, whilst the others can serve <code>fragment.73.js</code>. A user could make a request to an application which has a dependency on <code>fragment.74.js</code> but when it makes the request to fetch this resource, the load balancer could redirect it to an instance only containing <code>fragment.73.js</code>, causing a 404 on this resource.</p>\n<h2 id=\"references\">References</h2>\n<ul>\n<li><strong>Micro Frontends in Action</strong> (pages 178, 182)</li>\n</ul>","metaData":{"tags":["literature-note"]},"linksTo":["micro-frontends-in-action"],"label":"Deployment Synchronization"},{"id":"micro-frontends-in-action","type":"reference","label":"Micro Frontends in Action","linksTo":[],"bodyHtml":"<p class=\"paragraph\" ><strong>title</strong>: Micro Frontends in Action\n<strong>author</strong>: Michael Geers\n<strong>recommended by</strong>: na\n<strong>reading status</strong>: #reading \n<strong>tags</strong>: #micro-frontends, #architecture</p>","metaData":{"tags":["book","reference"]}}],"edges":[{"source":202101301828,"target":202101301829},{"source":202101301828,"target":202102071208},{"source":202101301828,"target":202102280947},{"source":202101301828,"target":202102241823},{"source":202101301828,"target":202102281124},{"source":202101301828,"target":"micro-frontends-in-action"},{"source":202101301829,"target":202101301828},{"source":202101301829,"target":"micro-frontends-in-action"},{"source":202102042224,"target":202102042246},{"source":202102042224,"target":202102071141},{"source":202102042224,"target":202102071605},{"source":202102042224,"target":"micro-frontends-in-action"},{"source":202102042232,"target":202102061841},{"source":202102042232,"target":202102071605},{"source":202102042232,"target":"micro-frontends-in-action"},{"source":202102042246,"target":202102042224},{"source":202102042246,"target":"micro-frontends-in-action"},{"source":202102061841,"target":202102062302},{"source":202102061841,"target":"micro-frontends-in-action"},{"source":202102062241,"target":202102071208},{"source":202102062241,"target":202102071240},{"source":202102062241,"target":"micro-frontends-in-action"},{"source":202102062302,"target":202102072253},{"source":202102062302,"target":202102071240},{"source":202102062302,"target":"micro-frontends-in-action"},{"source":202102071117,"target":202102042224},{"source":202102071117,"target":202102042232},{"source":202102071117,"target":"micro-frontends-in-action"},{"source":202102071141,"target":202102042224},{"source":202102071141,"target":"micro-frontends-in-action"},{"source":202102071208,"target":202102071605},{"source":202102071208,"target":202102062241},{"source":202102071208,"target":202102071240},{"source":202102071208,"target":"micro-frontends-in-action"},{"source":202102071240,"target":202102062241},{"source":202102071240,"target":202102062302},{"source":202102071605,"target":202102042224},{"source":202102071605,"target":202102042232},{"source":202102071605,"target":202102071117},{"source":202102071605,"target":202102071208},{"source":202102071605,"target":"micro-frontends-in-action"},{"source":202102072253,"target":202102121403},{"source":202102072253,"target":202102241823},{"source":202102072253,"target":202102281315},{"source":202102072253,"target":202102281316},{"source":202102072253,"target":"micro-frontends-in-action"},{"source":202102121403,"target":202102072253},{"source":202102121403,"target":"micro-frontends-in-action"},{"source":202102121749,"target":202102241823},{"source":202102131048,"target":202102241726},{"source":202102241726,"target":202101301828},{"source":202102241823,"target":202102121403},{"source":202102241823,"target":202102121749},{"source":202102241823,"target":"micro-frontends-in-action"},{"source":202102280947,"target":202101301828},{"source":202102280947,"target":"micro-frontends-in-action"},{"source":202102281039,"target":202102281124},{"source":202102281039,"target":"micro-frontends-in-action"},{"source":202102281124,"target":202101301828},{"source":202102281124,"target":202102281039},{"source":202102281124,"target":"micro-frontends-in-action"},{"source":202102281315,"target":"micro-frontends-in-action"},{"source":202102281316,"target":"micro-frontends-in-action"}]}})</script></main></body></html>